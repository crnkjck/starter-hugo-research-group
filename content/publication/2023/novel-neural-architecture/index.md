---
title: 'Snapture—a Novel Neural Architecture for Combined Static and Dynamic Hand Gesture Recognition'
authors:
  - Hassan Ali
  - Doreen Jirak
  - Stefan Wermter
date: '2023-07-17T00:00:00Z'
doi: '10.1007/s12559-023-10174-z'

# Schedule page publish date (NOT publication's date).
# publishDate: '2017-01-01T00:00:00Z'

# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types: [ '2' ]

# Publication name and optional abbreviated publication name.
publication: 'Cognitive Computation'
abstract: |
  As robots are expected to get more involved in people’s everyday lives, frameworks that enable intuitive user
  interfaces are in demand. Hand gesture recognition systems provide a natural way of communication and, thus, are an
  integral part of seamless human-robot interaction (HRI). Recent years have witnessed an immense evolution of
  computational models powered by deep learning. However, state-of-the-art models fall short of expanding across
  different gesture domains, such as emblems and co-speech. In this paper, we propose a novel hybrid hand gesture
  recognition system. Our Snapture architecture enables learning both static and dynamic gestures: by capturing a
  so-called snapshot of the gesture performance at its peak, we integrate the hand pose and the dynamic movement.
  Moreover, we present a method for analyzing the motion profile of a gesture to uncover its dynamic characteristics,
  which allows regulating a static channel based on the amount of motion. Our evaluation demonstrates the superiority of
  our approach on two gesture benchmarks compared to a state-of-the-art CNNLSTM baseline. Our analysis on a gesture
  class basis unveils the potential of our Snapture architecture for performance improvements using RGB data. Thanks to
  its modular implementation, our framework allows the integration of other multimodal data, like facial expressions and
  head tracking, which are essential cues in HRI scenarios, into one architecture. Thus, our work contributes both to
  integrative gesture recognition research and machine learning applications for non-verbal communication with robots.

tags:
  - Artificial Intelligence
  - Neural and Evolutionary Computing
  - Italian Institute of Technology
featured: false

links:
  - name: Cognitive Computation
    url: https://link.springer.com/journal/12559
# links:
#   - name: arXiv
#     url: https://arxiv.org/abs/2305.08528
#   - name: Other formats
#     url: https://arxiv.org/format/2305.08528
url_pdf: https://link.springer.com/content/pdf/10.1007/s12559-023-10174-z.pdf
# url_code: '#'
# url_dataset: '#'
# url_poster: '#'
# url_project: ''
# url_slides: ''
# url_source: '#'
# url_video: '#'

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# image:
#   caption: 'Image credit: [**Unsplash**](https://unsplash.com/photos/s9CC2SKySJM)'
#   focal_point: ''
#   preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
# projects:
#   - internal-project

# # Slides (optional).
# #   Associate this publication with Markdown slides.
# #   Simply enter your slide deck's filename without extension.
# #   E.g. `slides: "example"` references `content/slides/example/index.md`.
# #   Otherwise, set `slides: ""`.
# slides:
---
